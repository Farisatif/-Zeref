import fetch from 'node-fetch';
import 'dotenv/config'; // Ù…ÙÙŠØ¯ Ù„Ù„ØªØ¬Ø±Ø¨Ø© Ù…Ø­Ù„ÙŠÙ‹Ø§

let handler = async (m, { conn, text }) => {
  await conn.sendMessage(m.chat, { react: { text: 'ğŸ¤–', key: m.key } });
  if (!text) return m.reply("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø±\nÙ…Ø«Ø§Ù„:\n .Ø²ÙŠØ±ÙŠÙ Ù…Ø§ ÙØ§Ø¦Ø¯ØªÙƒØŸ");

  try {
    let result = await askOpenRouter(text);
    await m.reply(result);
  } catch (e) {
    await m.reply("Ø­Ø¯Ø« Ø®Ø·Ø£:\n" + e.message);
  }
};

handler.help = ["Ø²ÙŠØ±ÙŠÙ"];
handler.tags = ["ai"];
handler.command = /^Ø²ÙŠØ±ÙŠÙ$/i;

export default handler;

// ============ OpenRouter Function ============

async function askOpenRouter(prompt) {
  const apiKey = process.env.OPENROUTER_API_KEY;

  if (!apiKey) throw new Error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ OpenRouter");

  const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: "meta-llama/llama-3-8b-instruct",
      messages: [
        { role: "user", content: prompt }
      ]
    })
  });

  const data = await res.json();

  if (!res.ok) {
    throw new Error(data.error?.message || "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenRouter");
  }

  return data.choices?.[0]?.message?.content || "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø¯.";
}
